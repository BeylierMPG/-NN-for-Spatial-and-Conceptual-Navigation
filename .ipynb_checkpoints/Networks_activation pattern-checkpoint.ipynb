{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c36f7ccb-127b-44f0-917e-95fb9c9ed80d",
   "metadata": {},
   "source": [
    "First hidden layer: linear unit\n",
    "Second hiden layer: GELU for task 1 (output mapping is non linear)and linear for task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19666aaa-d26c-4245-9443-045bab24e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4838208b-92d9-42d3-bf43-2d38b92ecd99",
   "metadata": {},
   "source": [
    "REPRODUCIBILITY AND DEVICE INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99162be9-47fb-4f4f-b854-33a7e00fd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "\n",
    "# Call `set_seed` function to ensure reproducibility.\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# When `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77b7e1b8-a980-4f16-9e64-b19f5ad09820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd1e9d0fd10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "g_seed = torch.Generator()\n",
    "g_seed.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a64776e8-34e9-40ce-a6c6-46793f85abd8",
   "metadata": {},
   "source": [
    "\"VISUALIZATION TOOLS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319714ab-3ae6-4d0e-956c-7672a0b80ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b306775-0180-4035-80a3-da4525627281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Experiment:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Set the width and height of the grid\n",
    "        self.width = 8\n",
    "        self.height = 8\n",
    "        \n",
    "        self.Target_position_grid = np.eye(self.width,dtype=float)\n",
    "        for i in range(self.width-1):\n",
    "            self.Target_position_grid[i,i-1] = 1\n",
    "            self.Target_position_grid[i,i+1] = 1\n",
    "            \n",
    "        self.Target_position_grid[self.width-1,self.width-1] = 1\n",
    "        self.Target_position_grid[self.width-1,self.width - 2] = 1\n",
    "\n",
    "\n",
    "    def data_generator(self):\n",
    "        x = np.random.randint(0,7)\n",
    "        y = np.random.randint(0,7)\n",
    " \n",
    "        sun = np.random.random_sample()\n",
    "        rain = np.random.random_sample()\n",
    "        #data = torch.tensor([x/8,y/8,sun,rain])\n",
    "        target = self.Target_position_grid[x,y]\n",
    "        data = [x,y]      \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Create_Dataset(self,SIZE,BATCH_SIZE):\n",
    "        \n",
    "        data = [self.data_generator() for i in range(SIZE)]\n",
    "        target =[self.Target_position_grid[a[0],a[1]] for a in data]\n",
    "        data, target = torch.tensor(data,dtype=torch.float32), torch.tensor(target,dtype=torch.float32)\n",
    "\n",
    "        dataset = TensorDataset(data, target)\n",
    "        train_dataset, val_dataset = random_split(dataset, [int(np.floor(0.8*SIZE)), int(np.floor(0.2*SIZE))])\n",
    "        train_loader = DataLoader(dataset=train_dataset, \n",
    "                                  batch_size=BATCH_SIZE, \n",
    "                                  worker_init_fn=seed_worker,\n",
    "                                  generator=g_seed)\n",
    "        val_loader = DataLoader(dataset=val_dataset, \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                worker_init_fn=seed_worker,\n",
    "                                generator=g_seed)\n",
    "\n",
    "        return train_loader,val_loader\n",
    "\n",
    "#Proposition of 2 Networkds wooth diff number of neurons and layers\n",
    "\n",
    "class Net_Task1(torch.nn.Module):\n",
    "    def __init__(self,input_dimension, output_dimension):\n",
    "        super(Net_Task1, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features = input_dimension, out_features = 1)\n",
    "        self.fc2 = nn.Linear(in_features = 1, out_features = 2)\n",
    "        self.fc3 = nn.Linear(in_features = 2,  out_features = output_dimension)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Net_Task2(torch.nn.Module):\n",
    "    def __init__(self,input_dimension, output_dimension):\n",
    "        super(Net_Task2, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features = input_dimension, out_features = 5)\n",
    "        self.fc2 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        self.fc3 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        self.fc4 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        self.fc5 = nn.Linear(in_features = 5,  out_features = output_dimension)\n",
    "\n",
    "        #self.mask2 = torch.tensor([[1,0],[1,0],[0,1],[0,1]])\n",
    "        #self.mask3 = torch.tensor([[1,1,0,0],[0,0,1,1]]) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "class Training(Experiment):\n",
    "\n",
    "  # The class initialisation function.\n",
    "    def __init__(self,model,opti,loss):\n",
    "        self.model = model\n",
    "        self.optimizer = opti\n",
    "        self.criterion = loss\n",
    "    \n",
    "    def train_network(self,data,target):\n",
    "        Loss = []  \n",
    "        #Compute the prediction\n",
    "        output = self.model.forward(data)\n",
    "        # Calculate the loss for this transition.\n",
    "        loss =  self.criterion(output,target.unsqueeze(1))\n",
    "        # Set all the gradients stored in the optimiser to zero.\n",
    "        self.optimizer.zero_grad()\n",
    "        # Compute the gradients based on this loss, i.e. the gradients of the loss with respect to the Q-network parameters.\n",
    "        loss.backward()    \n",
    "        # Take one gradient step to update the Q-network. \n",
    "        self.optimizer.step()\n",
    "        # Return the loss as a scalar\n",
    "        \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b8b5a08-5d36-4740-88ff-12725823935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "Size_total_dataset = 1000\n",
    "Batch_size = 32\n",
    "n_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "experiment = Experiment()\n",
    "train_loader,val_loader = experiment.Create_Dataset(SIZE = Size_total_dataset,BATCH_SIZE = Batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "969cb5c8-ceb3-40ed-8009-481ae55b6d25",
   "metadata": {},
   "source": [
    "First Network with 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd12ca1-3361-4c0a-b449-6c4ed6b21749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n",
      "\n",
      " The model parameters before the update are: \n",
      "\n",
      "fc1.weight tensor([[-0.5226,  0.0189]])\n",
      "fc1.bias tensor([0.3430])\n",
      "fc2.weight tensor([[0.4318],\n",
      "        [0.1409]])\n",
      "fc2.bias tensor([-0.6695, -0.9114])\n",
      "fc3.weight tensor([[ 0.6545, -0.2909]])\n",
      "fc3.bias tensor([-0.5669])\n",
      "Size val_loader 7\n",
      "Size train_loader 25\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5226,  0.0189]], requires_grad=True), weight.grad None\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Net_Task1' object has no attribute 'fc4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c1d5d40f2b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-e671aca43a6e>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, data, target)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step {}, weight {}, weight.grad {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mweee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWeights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mweee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Compute the gradients based on this loss, i.e. the gradients of the loss with respect to the Q-network parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-54427e34e216>\u001b[0m in \u001b[0;36mcolor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mList_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mList_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net_Task1' object has no attribute 'fc4'"
     ]
    }
   ],
   "source": [
    "### MAIN ###\n",
    "set_seed(seed=SEED)\n",
    "model = Net_Task1(input_dimension = 2, output_dimension = 1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "experiment = Experiment()\n",
    "train = Training(model,optimizer,criterion)\n",
    "\n",
    "print('\\n The model parameters before the update are: \\n')\n",
    "print_params(model)\n",
    "\n",
    "print(\"Size val_loader\",len(val_loader))\n",
    "print(\"Size train_loader\",len(train_loader))\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = 0\n",
    "    val_loss = 0 \n",
    "    for x_batch, y_batch in train_loader:\n",
    "\n",
    "        loss += train.train_network(x_batch, y_batch).detach().numpy()\n",
    "    losses.append(loss/len(train_loader))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss += criterion( yhat,y_val.unsqueeze(1))\n",
    "        val_losses.append(val_loss.item()/len(val_loader))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_epoch = [i for i in range(len(losses))]\n",
    "l_epoch_val = [i for i in range(len(val_losses))]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(l_epoch,losses, '-', color='lightgrey', label='Train')\n",
    "plt.plot(l_epoch_val,val_losses, '-', label='Val')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6085f-aadc-41ac-bc5a-407195618512",
   "metadata": {},
   "source": [
    "2nd Network with 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef05bf35-b21c-483f-bfdd-e28253c90c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n",
      "\n",
      " The model parameters before the update are: \n",
      "\n",
      "fc1.weight tensor([[-0.5226,  0.0189],\n",
      "        [ 0.3430,  0.3053],\n",
      "        [ 0.0997, -0.4734],\n",
      "        [-0.6444,  0.6545],\n",
      "        [-0.2909, -0.5669]])\n",
      "fc1.bias tensor([ 0.4378, -0.6832,  0.4557, -0.5315,  0.3520])\n",
      "fc2.weight tensor([[-0.1245,  0.0117, -0.1825,  0.2535,  0.2151],\n",
      "        [ 0.2728, -0.1756,  0.4421,  0.0022, -0.1133],\n",
      "        [-0.4102,  0.3029, -0.3932, -0.2887, -0.1520],\n",
      "        [ 0.1661,  0.1753,  0.2955,  0.0193,  0.2181],\n",
      "        [ 0.2942, -0.4276, -0.3745, -0.4319, -0.3163]])\n",
      "fc2.bias tensor([ 0.2229,  0.3980,  0.1553, -0.3457,  0.2165])\n",
      "fc3.weight tensor([[ 0.2514,  0.3976, -0.4069, -0.0642, -0.2301],\n",
      "        [ 0.3902,  0.2490,  0.0541,  0.0279,  0.1907],\n",
      "        [-0.3510, -0.0451, -0.3350,  0.1596,  0.1386],\n",
      "        [-0.3891, -0.0191,  0.2076,  0.2254,  0.4219],\n",
      "        [-0.4032, -0.1394, -0.1829, -0.3782, -0.4269]])\n",
      "fc3.bias tensor([-0.3296,  0.2080, -0.3814, -0.2047, -0.2991])\n",
      "fc4.weight tensor([[-0.3441,  0.4038, -0.0477, -0.1492,  0.4077],\n",
      "        [-0.2581, -0.1893, -0.1455, -0.2996, -0.2140],\n",
      "        [-0.1078,  0.0333, -0.2632, -0.0174,  0.4405],\n",
      "        [ 0.0072, -0.0524, -0.4403, -0.3258,  0.2278],\n",
      "        [ 0.2678, -0.4218,  0.0961,  0.0944, -0.1756]])\n",
      "fc4.bias tensor([ 0.3493,  0.0661, -0.3411,  0.3765,  0.2067])\n",
      "fc5.weight tensor([[-0.2122,  0.0345,  0.3254,  0.3419,  0.2122]])\n",
      "fc5.bias tensor([0.1221])\n",
      "Size val_loader 7\n",
      "Size train_loader 25\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5226,  0.0189],\n",
      "        [ 0.3430,  0.3053],\n",
      "        [ 0.0997, -0.4734],\n",
      "        [-0.6444,  0.6545],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad None\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5216,  0.0199],\n",
      "        [ 0.3420,  0.3043],\n",
      "        [ 0.1007, -0.4724],\n",
      "        [-0.6454,  0.6555],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[-6.6336e-05, -1.6240e-05],\n",
      "        [ 3.9645e-03,  3.3388e-03],\n",
      "        [-2.0863e-03, -6.7090e-04],\n",
      "        [ 8.0152e-04, -2.5541e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5207,  0.0207],\n",
      "        [ 0.3410,  0.3035],\n",
      "        [ 0.1016, -0.4714],\n",
      "        [-0.6450,  0.6564],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[-3.3911e-05, -1.6589e-04],\n",
      "        [ 3.0851e-03,  8.1940e-04],\n",
      "        [-3.6507e-03, -6.2112e-04],\n",
      "        [-2.3119e-03, -6.6042e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(16)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5200,  0.0205],\n",
      "        [ 0.3400,  0.3026],\n",
      "        [ 0.1026, -0.4704],\n",
      "        [-0.6445,  0.6573],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000,  0.0003],\n",
      "        [ 0.0041,  0.0020],\n",
      "        [-0.0024, -0.0004],\n",
      "        [-0.0004, -0.0041],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5194,  0.0200],\n",
      "        [ 0.3391,  0.3020],\n",
      "        [ 0.1036, -0.4694],\n",
      "        [-0.6444,  0.6581],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000e+00,  3.2992e-04],\n",
      "        [ 1.0607e-03, -7.2390e-04],\n",
      "        [-5.6528e-03, -8.0512e-04],\n",
      "        [ 1.4303e-03, -8.7432e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5187,  0.0198],\n",
      "        [ 0.3383,  0.3014],\n",
      "        [ 0.1045, -0.4684],\n",
      "        [-0.6440,  0.6590],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[-3.6244e-05, -2.2037e-04],\n",
      "        [ 1.6576e-03,  1.0941e-03],\n",
      "        [-3.6056e-03, -8.6262e-04],\n",
      "        [-4.5252e-03, -1.0922e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(8)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(1)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5179,  0.0202],\n",
      "        [ 0.3376,  0.3009],\n",
      "        [ 0.1055, -0.4675],\n",
      "        [-0.6435,  0.6598],\n",
      "        [-0.2909, -0.5669]], requires_grad=True), weight.grad tensor([[-7.3110e-05, -6.7077e-04],\n",
      "        [-6.9621e-04, -5.6589e-04],\n",
      "        [-2.1736e-03, -5.1578e-04],\n",
      "        [-8.0215e-04, -4.4899e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5172,  0.0202],\n",
      "        [ 0.3369,  0.3004],\n",
      "        [ 0.1064, -0.4665],\n",
      "        [-0.6429,  0.6607],\n",
      "        [-0.2914, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000,  0.0005],\n",
      "        [ 0.0014,  0.0009],\n",
      "        [-0.0032, -0.0009],\n",
      "        [-0.0026, -0.0069],\n",
      "        [ 0.0003,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5165,  0.0201],\n",
      "        [ 0.3362,  0.3001],\n",
      "        [ 0.1074, -0.4655],\n",
      "        [-0.6422,  0.6616],\n",
      "        [-0.2919, -0.5669]], requires_grad=True), weight.grad tensor([[-3.6652e-05,  1.9245e-04],\n",
      "        [ 8.9408e-04, -8.6980e-04],\n",
      "        [-2.9850e-03, -3.4770e-04],\n",
      "        [-2.3822e-03, -7.6240e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5157,  0.0198],\n",
      "        [ 0.3355,  0.2997],\n",
      "        [ 0.1083, -0.4646],\n",
      "        [-0.6415,  0.6625],\n",
      "        [-0.2923, -0.5669]], requires_grad=True), weight.grad tensor([[-3.6490e-05,  3.7492e-04],\n",
      "        [ 2.1016e-03,  9.4982e-04],\n",
      "        [-4.8141e-03, -5.9213e-04],\n",
      "        [-6.0114e-04, -5.0246e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(3)\n",
      "aaaa tensor(5)\n",
      "aaaa tensor(9)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5149,  0.0195],\n",
      "        [ 0.3350,  0.2992],\n",
      "        [ 0.1093, -0.4636],\n",
      "        [-0.6408,  0.6635],\n",
      "        [-0.2926, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001,  0.0003],\n",
      "        [-0.0010,  0.0007],\n",
      "        [-0.0035, -0.0012],\n",
      "        [-0.0027, -0.0094],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5141,  0.0192],\n",
      "        [ 0.3343,  0.2987],\n",
      "        [ 0.1103, -0.4626],\n",
      "        [-0.6402,  0.6644],\n",
      "        [-0.2930, -0.5669]], requires_grad=True), weight.grad tensor([[-7.2712e-05, -1.3905e-04],\n",
      "        [ 4.7918e-03,  2.8757e-03],\n",
      "        [-5.2677e-03, -9.2288e-04],\n",
      "        [ 6.3539e-05, -3.3690e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5132,  0.0189],\n",
      "        [ 0.3335,  0.2980],\n",
      "        [ 0.1113, -0.4616],\n",
      "        [-0.6395,  0.6653],\n",
      "        [-0.2932, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001,  0.0002],\n",
      "        [ 0.0043,  0.0037],\n",
      "        [-0.0033, -0.0009],\n",
      "        [-0.0024, -0.0111],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5123,  0.0185],\n",
      "        [ 0.3327,  0.2973],\n",
      "        [ 0.1123, -0.4606],\n",
      "        [-0.6389,  0.6663],\n",
      "        [-0.2935, -0.5669]], requires_grad=True), weight.grad tensor([[-3.6241e-05,  2.7295e-04],\n",
      "        [ 2.3136e-03,  9.8267e-04],\n",
      "        [-4.7469e-03, -5.8749e-04],\n",
      "        [ 2.2364e-04, -3.1549e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5114,  0.0183],\n",
      "        [ 0.3320,  0.2966],\n",
      "        [ 0.1133, -0.4597],\n",
      "        [-0.6383,  0.6672],\n",
      "        [-0.2937, -0.5669]], requires_grad=True), weight.grad tensor([[-7.2759e-05, -2.5249e-04],\n",
      "        [ 1.1787e-03,  7.5782e-04],\n",
      "        [-3.7558e-03, -2.3226e-04],\n",
      "        [-6.2743e-04, -6.7694e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(22)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5104,  0.0182],\n",
      "        [ 0.3311,  0.2958],\n",
      "        [ 0.1143, -0.4587],\n",
      "        [-0.6376,  0.6681],\n",
      "        [-0.2939, -0.5669]], requires_grad=True), weight.grad tensor([[-8.3333e-05, -2.2171e-04],\n",
      "        [ 5.2425e-03,  3.9188e-03],\n",
      "        [-5.5800e-03, -9.8352e-04],\n",
      "        [-2.3811e-03, -8.5691e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5095,  0.0183],\n",
      "        [ 0.3303,  0.2951],\n",
      "        [ 0.1153, -0.4578],\n",
      "        [-0.6371,  0.6690],\n",
      "        [-0.2943, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001, -0.0007],\n",
      "        [ 0.0009,  0.0004],\n",
      "        [-0.0044, -0.0006],\n",
      "        [ 0.0012, -0.0022],\n",
      "        [ 0.0002,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5085,  0.0185],\n",
      "        [ 0.3295,  0.2943],\n",
      "        [ 0.1164, -0.4568],\n",
      "        [-0.6366,  0.6699],\n",
      "        [-0.2948, -0.5669]], requires_grad=True), weight.grad tensor([[-3.7706e-05, -1.2085e-04],\n",
      "        [ 3.5947e-03,  2.0522e-03],\n",
      "        [-6.4467e-03, -1.1073e-03],\n",
      "        [-8.8034e-04, -5.8849e-03],\n",
      "        [ 1.5382e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5076,  0.0188],\n",
      "        [ 0.3288,  0.2936],\n",
      "        [ 0.1174, -0.4559],\n",
      "        [-0.6362,  0.6708],\n",
      "        [-0.2953, -0.5669]], requires_grad=True), weight.grad tensor([[-7.7271e-05, -1.6770e-04],\n",
      "        [-1.3474e-04, -1.3227e-04],\n",
      "        [-2.3458e-03, -3.7338e-04],\n",
      "        [ 1.8417e-03, -3.2835e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(3)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5067,  0.0191],\n",
      "        [ 0.3280,  0.2929],\n",
      "        [ 0.1184, -0.4550],\n",
      "        [-0.6360,  0.6717],\n",
      "        [-0.2959, -0.5669]], requires_grad=True), weight.grad tensor([[-5.0859e-05, -4.0586e-04],\n",
      "        [ 7.4923e-04,  1.1264e-03],\n",
      "        [-3.6094e-03,  0.0000e+00],\n",
      "        [ 8.1078e-04, -5.6957e-03],\n",
      "        [ 1.5392e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5057,  0.0196],\n",
      "        [ 0.3273,  0.2922],\n",
      "        [ 0.1194, -0.4541],\n",
      "        [-0.6359,  0.6726],\n",
      "        [-0.2966, -0.5669]], requires_grad=True), weight.grad tensor([[-9.3349e-05, -4.6651e-04],\n",
      "        [ 2.7294e-03,  2.2185e-03],\n",
      "        [-5.1149e-03, -1.3271e-03],\n",
      "        [ 2.2029e-03, -2.9849e-03],\n",
      "        [ 3.0748e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5048,  0.0199],\n",
      "        [ 0.3265,  0.2915],\n",
      "        [ 0.1204, -0.4531],\n",
      "        [-0.6357,  0.6734],\n",
      "        [-0.2974, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000,  0.0002],\n",
      "        [ 0.0022,  0.0011],\n",
      "        [-0.0041, -0.0013],\n",
      "        [-0.0005, -0.0043],\n",
      "        [ 0.0002,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5040,  0.0203],\n",
      "        [ 0.3258,  0.2907],\n",
      "        [ 0.1215, -0.4521],\n",
      "        [-0.6357,  0.6742],\n",
      "        [-0.2982, -0.5669]], requires_grad=True), weight.grad tensor([[-4.3772e-05, -3.0700e-04],\n",
      "        [ 2.0965e-03,  1.2685e-03],\n",
      "        [-5.5199e-03, -1.3260e-03],\n",
      "        [ 9.9933e-04, -1.6428e-03],\n",
      "        [ 1.5341e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5032,  0.0207],\n",
      "        [ 0.3250,  0.2901],\n",
      "        [ 0.1225, -0.4511],\n",
      "        [-0.6356,  0.6750],\n",
      "        [-0.2990, -0.5669]], requires_grad=True), weight.grad tensor([[ 2.8144e-05,  1.6449e-04],\n",
      "        [ 8.6200e-04, -4.6595e-04],\n",
      "        [-7.4360e-03, -1.1662e-03],\n",
      "        [-1.6246e-03, -5.7266e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5025,  0.0211],\n",
      "        [ 0.3244,  0.2896],\n",
      "        [ 0.1235, -0.4501],\n",
      "        [-0.6356,  0.6758],\n",
      "        [-0.2999, -0.5669]], requires_grad=True), weight.grad tensor([[-3.8856e-05, -5.2803e-04],\n",
      "        [-1.1056e-03, -1.2694e-03],\n",
      "        [-2.3069e-03, -7.6070e-04],\n",
      "        [ 2.3785e-03, -3.4044e-03],\n",
      "        [ 3.0495e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(21)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5018,  0.0215],\n",
      "        [ 0.3239,  0.2892],\n",
      "        [ 0.1246, -0.4491],\n",
      "        [-0.6357,  0.6766],\n",
      "        [-0.3006, -0.5669]], requires_grad=True), weight.grad tensor([[-4.7832e-05,  4.0151e-05],\n",
      "        [ 1.4142e-04, -1.1917e-03],\n",
      "        [-5.1615e-03, -1.5521e-03],\n",
      "        [ 2.0644e-03, -3.3069e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5009,  0.0221],\n",
      "        [ 0.3232,  0.2887],\n",
      "        [ 0.1256, -0.4480],\n",
      "        [-0.6360,  0.6773],\n",
      "        [-0.3013, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0009],\n",
      "        [ 0.0032,  0.0026],\n",
      "        [-0.0056, -0.0017],\n",
      "        [ 0.0024, -0.0015],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.5001,  0.0226],\n",
      "        [ 0.3226,  0.2883],\n",
      "        [ 0.1267, -0.4469],\n",
      "        [-0.6361,  0.6781],\n",
      "        [-0.3020, -0.5669]], requires_grad=True), weight.grad tensor([[-5.0476e-05, -2.1584e-04],\n",
      "        [ 1.9067e-03,  4.0895e-04],\n",
      "        [-7.6474e-03, -1.6185e-03],\n",
      "        [-9.9002e-04, -5.7780e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(16)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4993,  0.0232],\n",
      "        [ 0.3219,  0.2878],\n",
      "        [ 0.1278, -0.4457],\n",
      "        [-0.6363,  0.6789],\n",
      "        [-0.3026, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000e+00,  2.8749e-05],\n",
      "        [ 2.8411e-03,  1.0829e-03],\n",
      "        [-4.9440e-03, -1.2090e-03],\n",
      "        [ 8.4428e-04, -4.1285e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4986,  0.0236],\n",
      "        [ 0.3212,  0.2873],\n",
      "        [ 0.1289, -0.4447],\n",
      "        [-0.6367,  0.6796],\n",
      "        [-0.3031, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000,  0.0001],\n",
      "        [ 0.0012, -0.0002],\n",
      "        [-0.0072, -0.0004],\n",
      "        [ 0.0034,  0.0020],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4979,  0.0241],\n",
      "        [ 0.3205,  0.2868],\n",
      "        [ 0.1300, -0.4436],\n",
      "        [-0.6368,  0.6803],\n",
      "        [-0.3036, -0.5669]], requires_grad=True), weight.grad tensor([[-5.9660e-05, -6.0523e-04],\n",
      "        [ 2.3716e-03,  1.9910e-03],\n",
      "        [-5.5652e-03, -1.1351e-03],\n",
      "        [-4.5421e-03, -1.2495e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(1)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4971,  0.0248],\n",
      "        [ 0.3199,  0.2865],\n",
      "        [ 0.1310, -0.4426],\n",
      "        [-0.6369,  0.6811],\n",
      "        [-0.3041, -0.5669]], requires_grad=True), weight.grad tensor([[-6.2874e-05, -4.3427e-04],\n",
      "        [-1.9167e-03, -2.1419e-03],\n",
      "        [-2.9612e-03, -5.1830e-04],\n",
      "        [ 1.9749e-04, -4.2268e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4965,  0.0253],\n",
      "        [ 0.3194,  0.2862],\n",
      "        [ 0.1321, -0.4416],\n",
      "        [-0.6368,  0.6819],\n",
      "        [-0.3047, -0.5669]], requires_grad=True), weight.grad tensor([[ 0.0000e+00, -9.5682e-05],\n",
      "        [ 9.2462e-04, -3.4670e-04],\n",
      "        [-5.9237e-03, -1.5510e-03],\n",
      "        [-1.5041e-03, -6.5249e-03],\n",
      "        [ 2.9895e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4957,  0.0260],\n",
      "        [ 0.3189,  0.2860],\n",
      "        [ 0.1332, -0.4406],\n",
      "        [-0.6367,  0.6828],\n",
      "        [-0.3052, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001, -0.0005],\n",
      "        [ 0.0002, -0.0006],\n",
      "        [-0.0037, -0.0003],\n",
      "        [-0.0019, -0.0086],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4949,  0.0267],\n",
      "        [ 0.3183,  0.2858],\n",
      "        [ 0.1343, -0.4395],\n",
      "        [-0.6367,  0.6836],\n",
      "        [-0.3057, -0.5669]], requires_grad=True), weight.grad tensor([[-9.6942e-05, -3.9958e-04],\n",
      "        [ 2.3233e-03,  1.0728e-03],\n",
      "        [-9.0540e-03, -1.7715e-03],\n",
      "        [ 7.8857e-04, -4.2891e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(3)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4939,  0.0275],\n",
      "        [ 0.3178,  0.2855],\n",
      "        [ 0.1353, -0.4385],\n",
      "        [-0.6365,  0.6845],\n",
      "        [-0.3062, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0005],\n",
      "        [ 0.0002,  0.0006],\n",
      "        [-0.0033, -0.0005],\n",
      "        [-0.0024, -0.0106],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(11)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4930,  0.0283],\n",
      "        [ 0.3173,  0.2852],\n",
      "        [ 0.1364, -0.4375],\n",
      "        [-0.6364,  0.6854],\n",
      "        [-0.3066, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001, -0.0007],\n",
      "        [ 0.0016,  0.0003],\n",
      "        [-0.0087, -0.0019],\n",
      "        [ 0.0009, -0.0034],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4919,  0.0293],\n",
      "        [ 0.3167,  0.2850],\n",
      "        [ 0.1375, -0.4364],\n",
      "        [-0.6362,  0.6864],\n",
      "        [-0.3070, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001, -0.0010],\n",
      "        [ 0.0024,  0.0007],\n",
      "        [-0.0075, -0.0022],\n",
      "        [-0.0010, -0.0117],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4909,  0.0303],\n",
      "        [ 0.3161,  0.2847],\n",
      "        [ 0.1387, -0.4352],\n",
      "        [-0.6362,  0.6873],\n",
      "        [-0.3074, -0.5669]], requires_grad=True), weight.grad tensor([[-8.2827e-05, -4.6244e-04],\n",
      "        [ 6.9986e-04, -2.6743e-04],\n",
      "        [-9.1628e-03, -1.6241e-03],\n",
      "        [ 2.2792e-03, -1.5432e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4898,  0.0313],\n",
      "        [ 0.3156,  0.2845],\n",
      "        [ 0.1399, -0.4341],\n",
      "        [-0.6362,  0.6882],\n",
      "        [-0.3077, -0.5669]], requires_grad=True), weight.grad tensor([[-2.7467e-04, -1.3455e-03],\n",
      "        [ 2.2956e-04, -8.8038e-05],\n",
      "        [-7.3625e-03, -1.3359e-03],\n",
      "        [-2.0890e-04, -8.4644e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(22)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4887,  0.0324],\n",
      "        [ 0.3151,  0.2843],\n",
      "        [ 0.1411, -0.4330],\n",
      "        [-0.6361,  0.6892],\n",
      "        [-0.3080, -0.5669]], requires_grad=True), weight.grad tensor([[-1.1401e-04, -7.3196e-04],\n",
      "        [ 1.2265e-03,  4.5952e-05],\n",
      "        [-9.2260e-03, -1.5948e-03],\n",
      "        [-2.9319e-04, -7.2710e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4875,  0.0336],\n",
      "        [ 0.3146,  0.2842],\n",
      "        [ 0.1423, -0.4318],\n",
      "        [-0.6362,  0.6901],\n",
      "        [-0.3084, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0013],\n",
      "        [-0.0001, -0.0005],\n",
      "        [-0.0075, -0.0014],\n",
      "        [ 0.0023, -0.0017],\n",
      "        [ 0.0001,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4863,  0.0349],\n",
      "        [ 0.3141,  0.2840],\n",
      "        [ 0.1435, -0.4306],\n",
      "        [-0.6362,  0.6910],\n",
      "        [-0.3089, -0.5669]], requires_grad=True), weight.grad tensor([[-9.1552e-05, -1.2904e-03],\n",
      "        [ 1.0820e-03,  3.3436e-04],\n",
      "        [-1.2029e-02, -2.7213e-03],\n",
      "        [-1.2459e-03, -8.5190e-03],\n",
      "        [ 1.4398e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4851,  0.0362],\n",
      "        [ 0.3138,  0.2839],\n",
      "        [ 0.1447, -0.4294],\n",
      "        [-0.6364,  0.6919],\n",
      "        [-0.3093, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0018],\n",
      "        [-0.0011, -0.0008],\n",
      "        [-0.0042, -0.0006],\n",
      "        [ 0.0031, -0.0039],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(5)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4839,  0.0375],\n",
      "        [ 0.3134,  0.2838],\n",
      "        [ 0.1458, -0.4286],\n",
      "        [-0.6367,  0.6928],\n",
      "        [-0.3098, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0016],\n",
      "        [-0.0001,  0.0004],\n",
      "        [-0.0013,  0.0018],\n",
      "        [ 0.0018, -0.0067],\n",
      "        [ 0.0001,  0.0000]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4827,  0.0389],\n",
      "        [ 0.3131,  0.2838],\n",
      "        [ 0.1470, -0.4276],\n",
      "        [-0.6370,  0.6937],\n",
      "        [-0.3105, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0001, -0.0019],\n",
      "        [ 0.0001, -0.0009],\n",
      "        [-0.0126, -0.0042],\n",
      "        [ 0.0036, -0.0034],\n",
      "        [ 0.0003,  0.0000]])\n",
      "None\n",
      "aaaa tensor(2)\n",
      "aaaa tensor(20)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4815,  0.0403],\n",
      "        [ 0.3128,  0.2838],\n",
      "        [ 0.1482, -0.4265],\n",
      "        [-0.6374,  0.6946],\n",
      "        [-0.3112, -0.5669]], requires_grad=True), weight.grad tensor([[-9.7476e-05, -8.9327e-04],\n",
      "        [ 1.5878e-04, -5.9814e-04],\n",
      "        [-9.2674e-03, -3.0156e-03],\n",
      "        [-5.6766e-04, -6.2196e-03],\n",
      "        [ 1.4262e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4803,  0.0416],\n",
      "        [ 0.3125,  0.2838],\n",
      "        [ 0.1494, -0.4254],\n",
      "        [-0.6378,  0.6954],\n",
      "        [-0.3120, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0012],\n",
      "        [ 0.0004, -0.0003],\n",
      "        [-0.0087, -0.0020],\n",
      "        [ 0.0017, -0.0019],\n",
      "        [ 0.0001,  0.0000]])\n",
      "None\n",
      "aaaa tensor(8)\n",
      "aaaa tensor(4)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4790,  0.0430],\n",
      "        [ 0.3123,  0.2839],\n",
      "        [ 0.1506, -0.4243],\n",
      "        [-0.6380,  0.6963],\n",
      "        [-0.3127, -0.5669]], requires_grad=True), weight.grad tensor([[-0.0002, -0.0010],\n",
      "        [-0.0008, -0.0016],\n",
      "        [-0.0099, -0.0013],\n",
      "        [-0.0024, -0.0086],\n",
      "        [ 0.0000,  0.0000]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(1)\n",
      "aaaa tensor(7)\n",
      "aaaa tensor(16)\n",
      "Step 1, weight Parameter containing:\n",
      "tensor([[-0.4779,  0.0444],\n",
      "        [ 0.3122,  0.2841],\n",
      "        [ 0.1518, -0.4232],\n",
      "        [-0.6384,  0.6972],\n",
      "        [-0.3135, -0.5669]], requires_grad=True), weight.grad tensor([[-4.7911e-05, -2.0362e-03],\n",
      "        [-1.3645e-03, -9.5647e-04],\n",
      "        [-4.4061e-03, -1.3313e-03],\n",
      "        [ 3.8158e-03, -4.1306e-03],\n",
      "        [ 2.8056e-04,  0.0000e+00]])\n",
      "None\n",
      "aaaa tensor(6)\n",
      "aaaa tensor(22)\n",
      "aaaa tensor(0)\n",
      "aaaa tensor(16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd1b8b13ee0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### MAIN ###\n",
    "set_seed(seed=SEED)\n",
    "model = Net_Task2(input_dimension = 2, output_dimension = 1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "experiment = Experiment()\n",
    "train = Training(model,optimizer,criterion)\n",
    "\n",
    "print('\\n The model parameters before the update are: \\n')\n",
    "print_params(model)\n",
    "\n",
    "print(\"Size val_loader\",len(val_loader))\n",
    "print(\"Size train_loader\",len(train_loader))\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loss = 0\n",
    "    val_loss = 0 \n",
    "    for x_batch, y_batch in train_loader:\n",
    "\n",
    "        loss += train.train_network(x_batch, y_batch).detach().numpy()\n",
    "    losses.append(loss/len(train_loader))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss += criterion( yhat,y_val.unsqueeze(1))\n",
    "        val_losses.append(val_loss.item()/len(val_loader))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_epoch = [i for i in range(len(losses))]\n",
    "l_epoch_val = [i for i in range(len(val_losses))]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(l_epoch,losses, '-', color='lightgrey', label='Train')\n",
    "plt.plot(l_epoch_val,val_losses, '-', label='Val')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be1099-b356-4df1-8ed3-ce1df8545bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
