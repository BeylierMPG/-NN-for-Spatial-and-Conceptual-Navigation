{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers_connexion(model,input_size):\n",
    "    Layers = 1 #input layer\n",
    "    Connexions = []\n",
    "    Nodes = [input_size]\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            if \"bias\" in name:\n",
    "                Layers += 1\n",
    "                Nodes.append(len(param.detach().numpy()))\n",
    "            else:\n",
    "                a = param.detach().numpy()\n",
    "            #Replace weight value by binary number\n",
    "                a = np.select( [a != 0.0, a== 0.0], [1,0],default = a)\n",
    "                a = np.array(a)\n",
    "                Connexions.append(a)\n",
    "    return(Layers, Connexions, Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_Task2(torch.nn.Module):\n",
    "    def __init__(self,input_dimension, output_dimension):\n",
    "        super(Net_Task2, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features = input_dimension, out_features = 5)\n",
    "        self.fc2 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        self.fc3 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        #self.fc4 = nn.Linear(in_features = 5, out_features = 5)\n",
    "        #self.fc5 = nn.Linear(in_features = 5,  out_features = output_dimension)\n",
    "        self.fc4 = nn.Linear(in_features = 5,  out_features = output_dimension)\n",
    "\n",
    "        #self.mask2 = torch.tensor([[1,0],[1,0],[0,1],[0,1]])\n",
    "        #self.mask3 = torch.tensor([[1,1,0,0],[0,0,1,1]]) \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #x = F.relu(self.fc4(x))\n",
    "        #x = self.fc5(x)\n",
    "        x = self.fc4(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "class Net_Task1(torch.nn.Module):\n",
    "    def __init__(self,input_dimension, output_dimension):\n",
    "        super(Net_Task1, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features = input_dimension, out_features = 1)\n",
    "        self.fc2 = nn.Linear(in_features = 1, out_features = 2)\n",
    "        self.fc3 = nn.Linear(in_features = 2,  out_features = output_dimension)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The model parameters before the update are: \n",
      "\n",
      "fc1.weight tensor([[ 0.3438, -0.3645, -0.2179,  0.1977,  0.2077],\n",
      "        [ 0.1628, -0.1337, -0.1047,  0.0086,  0.2361],\n",
      "        [-0.0203,  0.4032, -0.1586, -0.1919,  0.2630],\n",
      "        [-0.4333, -0.0190,  0.0519,  0.1863, -0.2896],\n",
      "        [ 0.0324,  0.0712,  0.3107, -0.1679, -0.3326]])\n",
      "fc1.bias tensor([ 0.1212, -0.2219,  0.4222,  0.3586, -0.3397])\n",
      "fc2.weight tensor([[-0.3704,  0.2508, -0.0796, -0.0917, -0.2026],\n",
      "        [-0.1882, -0.4452, -0.2178,  0.1285,  0.4225],\n",
      "        [ 0.3439, -0.3233,  0.0090, -0.2158, -0.1013],\n",
      "        [ 0.3259,  0.3778, -0.1262, -0.3755, -0.1559],\n",
      "        [-0.2813, -0.3646, -0.0117, -0.3899,  0.1150]])\n",
      "fc2.bias tensor([ 0.2860,  0.0238, -0.3747,  0.1253,  0.3516])\n",
      "fc3.weight tensor([[-0.1678, -0.3700,  0.1195, -0.1478,  0.1883],\n",
      "        [-0.1499,  0.2549,  0.2908, -0.0652,  0.0855],\n",
      "        [-0.0502, -0.1304,  0.1478, -0.3118,  0.0192],\n",
      "        [ 0.1198,  0.0637, -0.2314,  0.3651, -0.3822],\n",
      "        [-0.1498, -0.1195,  0.3971, -0.1322, -0.4169]])\n",
      "fc3.bias tensor([-0.1320,  0.0024, -0.3193, -0.0272,  0.1006])\n",
      "fc4.weight tensor([[-0.4453, -0.4264, -0.2683,  0.1978, -0.2952]])\n",
      "fc4.bias tensor([0.0223])\n"
     ]
    }
   ],
   "source": [
    "model = Net_Task2(input_dimension = 5, output_dimension = 1)\n",
    "print('\\n The model parameters before the update are: \\n')\n",
    "print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-009f3f08d9d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Optionally, show the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplay_on\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-181-c2f0e655a25d>\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Environment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# This line is necessary to give time for the image to be rendered on the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network_Visualization:\n",
    "    def __init__(self,display,magnification,Model,input_size):\n",
    "        self.layers,self.connexions,self.nodes = layers_connexion(model,input_size)\n",
    "        # Set whether the environment should be displayed after every step\n",
    "        self.display = display\n",
    "        # Set the magnification factor of the display\n",
    "        self.magnification = magnification\n",
    "        # Create an image which will be used to display the environment\n",
    "        self.image = np.zeros([int(self.magnification), int(self.magnification), 3], dtype=np.uint8)\n",
    "        # Set the width and height of the environment\n",
    "        self.width = 5\n",
    "        self.height = 5\n",
    "        self.rayon = 20\n",
    "            \n",
    "        # Init y coordinates of each layers\n",
    "        self.b = np.linspace(4* self.rayon,\n",
    "                        self.magnification-4*self.rayon,\n",
    "                        self.layers)\n",
    "        # Init coordinates of each nodes, i//self.layers allow to have the same y coordinates for every nodes of the same layer\n",
    "        self.Nodes_coordinates = []\n",
    "        \n",
    "    def draw(self):\n",
    "        # Create the background image\n",
    "        window_top_left = (0, 0)\n",
    "        window_bottom_right = (self.magnification , self.magnification )\n",
    "        cv2.rectangle(self.image, window_top_left, window_bottom_right, (255, 255, 255), thickness=cv2.FILLED)\n",
    "        for i in range(self.layers):\n",
    "            a = np.linspace(4* self.rayon,\n",
    "                            self.magnification-4*self.rayon,\n",
    "                            self.nodes[i])\n",
    "            coordinates = [[int(a[j]),int(self.b[i])] for j in range(len(a))]\n",
    "            self.Nodes_coordinates.append(coordinates)     \n",
    "            \n",
    "        #Draw the Nodes\n",
    "        \n",
    "        for i in range(self.layers):\n",
    "            for j in range(len(self.Nodes_coordinates[i])):\n",
    "                cv2.circle(self.image,center= self.Nodes_coordinates[i][j], \n",
    "                           radius = self.rayon, \n",
    "                           color =(139,139,0), \n",
    "                           thickness = 2 )\n",
    "        #Draw the connexions\n",
    "        for i in reversed(range(1, self.layers )):\n",
    "            g = self.connexions[i-1].shape\n",
    "            for j in range(g[0]):\n",
    "                for k in range(g[1]):\n",
    "                    if self.connexions[i-1][j][k] != 0:\n",
    "                      \n",
    "                        cv2.line(self.image, \n",
    "                                 pt1 = np.array(self.Nodes_coordinates[i-1][k]) + [0,self.rayon], \n",
    "                                 pt2 = np.array(self.Nodes_coordinates[i][j]) - [0,self.rayon],\n",
    "                                 color =  (238,229,142) , \n",
    "                                 thickness = 2)\n",
    "\n",
    "        cv2.imshow(\"Neural Network\", self.image)\n",
    "        # This line is necessary to give time for the image to be rendered on the screen\n",
    "        cv2.waitKey(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_on = True\n",
    "visu = Network_Visualization(display = display_on,magnification=800,Model = model,input_size=5)\n",
    "\n",
    "# Determine the time at which training will stop, i.e. in 10 minutes (600 seconds) time\n",
    "start_time = time.time() \n",
    "end_time = start_time + 30\n",
    "visu.draw()\n",
    "#while time.time() < end_time:\n",
    "# Optionally, show the environment\n",
    " #   if display_on:\n",
    "  #      visu.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [[0, 6720.0], [0, 6720.0], [0, 6720.0], [0, 6720.0], [0, 6720.0], [0, 6560.0], [0, 6560.0], [0, 6560.0], [0, 6560.0], [0, 6560.0], [0, 6400.0], [0, 6400.0], [0, 6400.0], [0, 6400.0], [0, 6400.0], [0, 6240.0], [0, 6240.0], [0, 6240.0], [0, 6240.0], [0, 6240.0], [0, 6080.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      z_ = np.select( (z_==1,z_==2, z_==3),\n",
    "                (150, 120, 110),\n",
    "                default=z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "magnification = 800\n",
    "height = 5\n",
    "width = 5\n",
    "image = np.zeros([int(magnification), int(magnification), 3], dtype=np.uint8)\n",
    "window_top_left = (0, 0)\n",
    "window_bottom_right = (magnification*height, magnification*width)\n",
    "cv2.rectangle(image, window_top_left, window_bottom_right, (0, 238, 229), thickness=cv2.FILLED)\n",
    "cv2.imshow(\"Environment6\",image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(3<4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
